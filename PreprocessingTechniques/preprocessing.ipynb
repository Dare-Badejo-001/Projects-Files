{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  Score_Mean  Score_Median  Score_Mode\n",
      "0   25.0        25.0          25.0        25.0\n",
      "1    NaN        29.0          29.5        25.0\n",
      "2   30.0        30.0          30.0        30.0\n",
      "3    NaN        29.0          29.5        25.0\n",
      "4   29.0        29.0          29.0        29.0\n",
      "5   27.0        27.0          27.0        27.0\n",
      "6   32.0        32.0          32.0        32.0\n",
      "7   31.0        31.0          31.0        31.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample data\n",
    "data = {'Score': [25, np.nan, 30, np.nan, 29, 27, 32, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mean Imputation\n",
    "df['Score_Mean'] = df['Score'].fillna(df['Score'].mean())\n",
    "\n",
    "# Median Imputation\n",
    "df['Score_Median'] = df['Score'].fillna(df['Score'].median())\n",
    "\n",
    "# Mode Imputation\n",
    "df['Score_Mode'] = df['Score'].fillna(df['Score'].mode()[0])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming the same initial data with missing values\n",
    "data = {'Feature1': [25, 20, 30, 40, 29, 27, 32, 31],\n",
    "        'Feature2': [20, 25, np.nan, 45, 30, 25, 35, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Predictive Imputation using KNN\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_filled = imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's assume a time series data with missing values\n",
    "time_data = {'Time': pd.date_range(start='1/1/2023', periods=8, freq='D'),\n",
    "             'Value': [1, np.nan, np.nan, 4, 5, np.nan, 7, 8]}\n",
    "df_time = pd.DataFrame(time_data)\n",
    "\n",
    "# LOCF\n",
    "df_time['Value_LOCF'] = df_time['Value'].fillna(method='ffill')\n",
    "\n",
    "# NOCB\n",
    "df_time['Value_NOCB'] = df_time['Value'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def select_feature_rfe(data, target, n_features_to_select=5): \n",
    "    model = LogisticRegression(solver='liblinear') \n",
    "    rfe = RFE(model, n_features_to_select=n_features_to_select)\n",
    "    fit = rfe.fit(data, target) \n",
    "\n",
    "    selected_features = [f for f, s in zip(data.columns, fit.support_) if s]\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def apply_pca(data, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principalComponents = pca.fit_transform(data)\n",
    "    return pd.DataFrame(data=principalComponents, columns=[f'PC{i+1}' for i in range(n_components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return pd.DataFrame(scaled_data, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_hyperparameters(model, param_grid, X_train, y_train, cv=5):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_smote\u001b[39m(X, y):\n\u001b[0;32m      4\u001b[0m     smote \u001b[38;5;241m=\u001b[39m SMOTE()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def apply_smote(X, y):\n",
    "    smote = SMOTE()\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
